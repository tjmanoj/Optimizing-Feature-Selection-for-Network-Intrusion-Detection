{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Google drive, directory change, imports**"
      ],
      "metadata": {
        "id": "RB511P3hmkUu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tULoJr4DybUb"
      },
      "outputs": [],
      "source": [
        "#google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBrVOm6EzMC8"
      },
      "outputs": [],
      "source": [
        "#title dir-change\n",
        "import os\n",
        "folder_path = \"/content/drive/MyDrive/MH_Algorithms\"\n",
        "os.chdir(folder_path)\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9AyjP-xz8EP"
      },
      "outputs": [],
      "source": [
        "#necessary imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training data process**"
      ],
      "metadata": {
        "id": "DyAm75wFmtEH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CYI8aPWpOaZ"
      },
      "outputs": [],
      "source": [
        "#load training data:: UNSW_NB15_training-set.csv\n",
        "data_read = pd.read_csv('/content/drive/MyDrive/datasets/UNSW_NB15_training-set.csv')\n",
        "\n",
        "#drop 'id', 'attack_cat', 'label' columns\n",
        "data_1 = data_read\n",
        "data_1 = data_1.drop(['id', 'attack_cat', 'label'], axis = 1)\n",
        "\n",
        "#convert 'proto', 'state' and 'service' column values to numeric values\n",
        "le = LabelEncoder()\n",
        "proto = le.fit_transform(data_1['proto'])\n",
        "data_1.drop(\"proto\", axis=1, inplace=True)\n",
        "data_1[\"proto\"] = proto\n",
        "\n",
        "state = le.fit_transform(data_1['state'])\n",
        "data_1.drop(\"state\", axis=1, inplace=True)\n",
        "data_1[\"state\"] = state\n",
        "\n",
        "service = le.fit_transform(data_1['service'])\n",
        "data_1.drop(\"service\", axis=1, inplace=True)\n",
        "data_1[\"service\"] = service\n",
        "\n",
        "#take only the values without column names\n",
        "data_1 = data_1.values\n",
        "train_feat = np.asarray(data_1[:, :])\n",
        "\n",
        "#process only labels\n",
        "data_2 = data_read.values\n",
        "train_label = np.asarray(data_2[:, -1])\n",
        "train_label = train_label.astype('int')\n",
        "\n",
        "#perform data normalization\n",
        "scaler = preprocessing.StandardScaler().fit(train_feat)\n",
        "train_minmax_feat = scaler.transform(train_feat)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Data Process**"
      ],
      "metadata": {
        "id": "5t3xwhLKmwcm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DkCEVaSZNLT"
      },
      "outputs": [],
      "source": [
        "#load test data:: UNSW_NB15_testing-set.csv\n",
        "test_data_read = pd.read_csv('/content/drive/MyDrive/datasets/UNSW_NB15_testing-set.csv')\n",
        "\n",
        "#drop 'id', 'attack_cat', 'label' columns\n",
        "test_data_1 = test_data_read\n",
        "test_data_1 = test_data_1.drop(['id', 'attack_cat', 'label'], axis = 1)\n",
        "\n",
        "#convert 'proto', 'state' and 'service' column values to numeric values\n",
        "test_le = LabelEncoder()\n",
        "proto = test_le.fit_transform(test_data_1['proto'])\n",
        "test_data_1.drop(\"proto\", axis=1, inplace=True)\n",
        "test_data_1[\"proto\"] = proto\n",
        "\n",
        "state = test_le.fit_transform(test_data_1['state'])\n",
        "test_data_1.drop(\"state\", axis=1, inplace=True)\n",
        "test_data_1[\"state\"] = state\n",
        "\n",
        "service = test_le.fit_transform(test_data_1['service'])\n",
        "test_data_1.drop(\"service\", axis=1, inplace=True)\n",
        "test_data_1[\"service\"] = service\n",
        "\n",
        "#take only the values without column names\n",
        "test_data_1 = test_data_1.values\n",
        "test_feat = np.asarray(test_data_1[:, :])\n",
        "\n",
        "#process only labels\n",
        "test_data_2 = test_data_read.values\n",
        "test_label = np.asarray(test_data_2[:, -1])\n",
        "test_label = test_label.astype('int')\n",
        "\n",
        "#perform data normalization\n",
        "test_scaler = preprocessing.StandardScaler().fit(test_feat)\n",
        "test_scaled_feat = test_scaler.transform(test_feat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDC3FD2iZczm"
      },
      "source": [
        "**There are four Meta Heuristics model available.**\n",
        "\n",
        "> * **Particle Swarm Optimization** (use `pso` as short form)\n",
        "*   **Sine Cosine Algorithm** (use `sca` as short form)\n",
        "*   **Flower Pollination Algorithm** (use `fpa` as short form)\n",
        "*   **Differential Evolution** (use `de` as short form)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First model selection and feature selection**"
      ],
      "metadata": {
        "id": "JjnVbNcOm2du"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw6kBQS2RAoC"
      },
      "outputs": [],
      "source": [
        "#import the first MH model\n",
        "#@title # Select First Model\n",
        "import importlib\n",
        "model_selected = 'sca' #@param ['pso', 'sca', 'fpa', 'de'] {allow-input: true}\n",
        "var = importlib.import_module(model_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_BzKZ6K1wSx"
      },
      "outputs": [],
      "source": [
        "# split data into train & validation (80 -- 20)\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(train_minmax_feat, train_label, test_size=0.2, stratify=train_label)\n",
        "fold = {'xt':xtrain, 'yt':ytrain, 'xv':xtest, 'yv':ytest}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_Xi6WOyfNCE"
      },
      "source": [
        "**Parameter List**\n",
        "\n",
        "> **PSO contains 3 extra parameters.**\n",
        "*   c1  = 2     # cognitive factor\n",
        "* c2  = 2         # social factor \n",
        "* w   = 0.9       # inertia weight\n",
        "\n",
        "> **SCA contains 1 extra parameter**\n",
        "* alpha  = 2    # constant\n",
        "\n",
        "> **FPA contains 1 extra parameter**\n",
        "* P  = 0.8      # switch probability\n",
        "\n",
        "> **CS contains 1 extra parameter**\n",
        "* Pa  = 0.25   # discovery rate\n",
        "\n",
        "> **DE contains 2 extra parameters**\n",
        "* CR = 0.9    # crossover rate\n",
        "* F  = 0.5    # constant factor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT30kZ9o18rR"
      },
      "outputs": [],
      "source": [
        "# set parameters:: change the values and update dictionary fields in \"opts\"\n",
        "k    = 5     # k-value in KNN\n",
        "N    = 10    # number of particles\n",
        "T    = 50    # maximum number of iterations\n",
        "#w    = 0.9\n",
        "#c1   = 0.5\n",
        "#c2   = 0.5\n",
        "opts = {'k':k, 'fold':fold, 'N':N, 'T':T, 'alpha':2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUSPCinT2Ge8"
      },
      "outputs": [],
      "source": [
        "# perform feature selection (first model)\n",
        "fmdl = var.jfs(train_minmax_feat, train_label, opts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jQBvIOc2oYR"
      },
      "outputs": [],
      "source": [
        "# selected features and number of selected features from first model\n",
        "sel_feat = fmdl['sf']\n",
        "print(\"Selected Features:\", sel_feat)\n",
        "num_feat = fmdl['nf']\n",
        "print(\"Feature Size:\", num_feat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPnxjIGc2vLa"
      },
      "outputs": [],
      "source": [
        "# plot convergence\n",
        "curve   = fmdl['c']\n",
        "curve   = curve.reshape(np.size(curve,1))\n",
        "x       = np.arange(0, opts['T'], 1.0) + 1.0\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x, curve, 'o-')\n",
        "ax.set_xlabel('Number of Iterations')\n",
        "ax.set_ylabel('Cost as Fitness')\n",
        "ax.set_title(model_selected)\n",
        "ax.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaBCXZmixhrL"
      },
      "source": [
        "**Second model selection and Feature Selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUgPoq0I2yAc"
      },
      "outputs": [],
      "source": [
        "# data with selected features from first model\n",
        "num_train = np.size(xtrain, 0)\n",
        "x_train   = xtrain[:, sel_feat]\n",
        "y_train   = ytrain.reshape(num_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSJAJxylBrJA"
      },
      "outputs": [],
      "source": [
        "#import the second MH model\n",
        "#@title # Select Second Model\n",
        "import importlib\n",
        "model2_selected = 'pso' #@param ['pso', 'sca', 'fpa', 'de'] {allow-input: true}\n",
        "var2 = importlib.import_module(model2_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "979lVM9EBvfw"
      },
      "outputs": [],
      "source": [
        "# split data with reduced feature set into train & validation (80 -- 20)\n",
        "fxtrain, fxtest, fytrain, fytest = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train)\n",
        "fold = {'xt':fxtrain, 'yt':fytrain, 'xv':fxtest, 'yv':fytest}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU95WfxRB3ix"
      },
      "outputs": [],
      "source": [
        "# set parameters:: change the values and update dictionary fields in \"smdl_opts\"\n",
        "k    = 5     # k-value in KNN\n",
        "N    = 10    # number of particles\n",
        "T    = 50     # maximum number of iterations\n",
        "w    = 0.9\n",
        "c1   = 0.5\n",
        "c2   = 1.5\n",
        "smdl_opts = {'k':k, 'fold':fold, 'N':N, 'T':T, 'c1':1.5, 'c2':2,'w':0.9}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxk0Fk7Oxg1O"
      },
      "outputs": [],
      "source": [
        "# perform feature selection (second model)\n",
        "smdl = var2.jfs(x_train, y_train, smdl_opts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKG20KOdocSY"
      },
      "outputs": [],
      "source": [
        "# selected feature list and number of selected features from second model\n",
        "smdl_sel_feat = smdl['sf']\n",
        "print(\"Selected Features:\", smdl_sel_feat)\n",
        "smdl_num_feat = smdl['nf']\n",
        "print(\"Feature Size:\", smdl_num_feat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsPPQGKc-wIi"
      },
      "outputs": [],
      "source": [
        "# plot convergence\n",
        "smdl_curve   = smdl['c']\n",
        "smdl_curve   = smdl_curve.reshape(np.size(smdl_curve,1))\n",
        "smdl_x       = np.arange(0, smdl_opts['T'], 1.0) + 1.0\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(smdl_x, smdl_curve, 'o-')\n",
        "ax.set_xlabel('Number of Iterations')\n",
        "ax.set_ylabel('Cost as Fitness')\n",
        "ax.set_title(model2_selected)\n",
        "ax.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgUXvdBbuj2q"
      },
      "source": [
        "**Classification results on Test DataSet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo8I7x4Colwh"
      },
      "outputs": [],
      "source": [
        "# Load test data with finally selected features\n",
        "num_valid = np.size(test_scaled_feat, 0)\n",
        "x_valid   = test_scaled_feat[:, smdl_sel_feat]\n",
        "y_valid   = test_label.reshape(num_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhN9l_PTunUK"
      },
      "outputs": [],
      "source": [
        "#classification using J48, Random Forest and SVC using 5-fold cross validation with performance evaluation metrics\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "import time\n",
        "\n",
        "clf1 = DecisionTreeClassifier(criterion = \"entropy\", random_state = 42, max_depth=3, min_samples_leaf=5)\n",
        "clf2 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "clf3 = SVC(kernel='linear', probability=True)\n",
        "\n",
        "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
        "           'precision' : make_scorer(precision_score),\n",
        "           'recall' : make_scorer(recall_score), \n",
        "           'f1_score' : make_scorer(f1_score)}\n",
        "\n",
        "for clf, label in zip([clf1, clf2], ['J48', 'Random Forest', 'SVM']):\n",
        "  start_time = time.time()\n",
        "  scores = cross_validate(clf, x_valid, y_valid, scoring=scoring, cv=5)\n",
        "  print(\"Accuracy: %0.4f Precision: %0.4f Recall: %0.4f F-score: %0.4f [%s]\" % (scores['test_accuracy'].mean(), scores['test_precision'].mean(), scores['test_recall'].mean(), scores['test_f1_score'].mean(), label))\n",
        "  end_time = time.time()\n",
        "  exec_time = end_time - start_time\n",
        "  print(\"Time:\", exec_time)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Feature Selection Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}